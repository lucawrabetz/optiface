from collections import OrderedDict
from datetime import datetime
from typing import Any

from pathlib import Path

from pandas import DataFrame
from sqlalchemy import Engine, create_engine, engine
from sqlalchemy import (
    MetaData,
    Table,
    Column,
    Integer,
    String,
    Float,
    DateTime,
    Boolean,
    Inspector,
    inspect,
    insert,
)

from optiface.core.optispace import (
    ProblemSpace,
    Feature,
    run_key_features,
)

from optiface.core.featuredata import _RUN_KEY_DATA

from optiface.core.optidatetime import OptiDateTimeFactory

from optiface.constants import _SQLITE_PREF, _SPACE, _EXPERIMENTS_DBFILE

# TODO: refactor to SQL query file
# TODO: (CREATE TABLE) to init new table based on pspace config (i.e. columns)
# TODO: (INSERT INTO) inserting columns using pspace config
_DEFAULT_PSPACE = "defaultproblem"

_DEFAULT_ROW = ("MANUAL", "faketest", 1, 0, "MYSOLVER", 100.0, 1000.0)
_ASPI_TEST_ROW = (
    "MANUAL",
    "faketest",
    10,
    100,
    5,
    0.1,
    10,
    5,
    3,
    0,
    "MIP",
    "NA",
    100.0,
    1000.0,
    0,
    1,
    0.0,
    -1,
    -1,
    -1.0,
    -1.0,
    "0-0-0-0-0-0-0-1-2-2",
    -1,
    -1,
)
_ADDED_FROM_CSV: str = "CSV"
_RESULTS_TABLE_NAME = "results"

feature_to_alchemy_types: dict[type, type] = {
    str: String,
    int: Integer,
    float: Float,
    bool: Boolean,
    datetime: DateTime,
}


class AlchemyWAPI:
    def __init__(self, pspace: ProblemSpace, engine: Engine, metadata: MetaData):
        self.pspace: ProblemSpace = pspace
        self.odtf = OptiDateTimeFactory()
        self.engine: Engine = engine
        self.metadata: MetaData = metadata

    def row_values_to_dict(self, row: list[Any]) -> OrderedDict[str, Any]:
        # TODO: combine AlchemyWAPI.row_values_to_dict and ProblemSpace.validate to only iterate over row once when we decide how to
        # handle errors more gracefully (we can avoid having the validate method return a bool)
        # generally part of an obviously needed refactor to create a cleaner api between pspace feature and alchemy column
        # its stinky up in here
        feature_names: list[str] = [fname for fname in _RUN_KEY_DATA.keys()]
        feature_names.extend([f.name for f in self.pspace.full_row()])
        row_value_dict = OrderedDict()

        for f, val in zip(feature_names, row):
            row_value_dict[f] = val

        return row_value_dict

    def insert_single_row(self, row_values: list[Any]) -> None:
        row_dict = self.row_values_to_dict(row_values)
        stmt = insert(self.metadata.tables[_RESULTS_TABLE_NAME]).values(**row_dict)
        stmt.compile()

        with self.engine.connect() as conn:
            conn.execute(stmt)
            conn.commit()
            print(f"added one row to results table in problem {self.pspace.name}")

    def insert_rows(self, df: DataFrame) -> None:
        for _, csv_row in df.iterrows():
            csv_row = list(csv_row)
            valid = self.pspace.validate_row(csv_row)

            # validate - does not validate the run key (run_id, time_added, added_from), this is generated by us
            if not valid:
                print(f"skipping non-valid row: {csv_row}")
                continue

            row = [self.odtf.optinow(), _ADDED_FROM_CSV]
            row.extend(csv_row)
            self.insert_single_row(row)

    def results_table_head(self):
        pass
        # res = self.cur.execute(_SQL_GETALL_RESULTS)
        # row = res.fetchone()
        # print(row)


class AlchemyFactory:
    def __init__(self, pspace: ProblemSpace):
        self.pspace: ProblemSpace = pspace
        self.dbpath: Path = Path(_SPACE) / pspace.name / _EXPERIMENTS_DBFILE

        # create_engine does not create db file if it DNE
        self.engine: Engine = create_engine(_SQLITE_PREF + str(self.dbpath), echo=True)
        # inspecting creates db file if it DNE
        self.inspector: Inspector = inspect(self.engine)

    # TODO: needs to return error or AlchemyWAPI
    def check_and_init_db(self):
        tables: list[str] = self.inspector.get_table_names()

        # generic runtime error / unresolvable based on table names
        # other unknown tables in database
        if len(tables) > 1 or (len(tables) == 1 and tables[0] != _RESULTS_TABLE_NAME):
            raise RuntimeError(
                f"I cannot reconcile the problemspace {self.pspace.name} with its database"
            )

        # changes needed
        # no results table
        if len(tables) == 0:
            return self.create_db()

        # tables are correct, validate (check columns against problemspace), (no migration yet, missing columns raise error, alembic soon?), reflect
        if tables == [_RESULTS_TABLE_NAME]:
            # validate and reflect
            columns = self.inspector.get_columns(_RESULTS_TABLE_NAME)

            feature_names = [f for f in _RUN_KEY_DATA.keys()]

            feature_names.extend([f.name for f in self.pspace.full_row()])

            fnames = set(feature_names)

            # refactor column | feature interface
            for c in columns:
                print(c)
                if c["name"] == "run_id" and c["primary_key"] == 0:
                    raise RuntimeError(
                        f"I cannot reconcile the problemspace {self.pspace.name} with its database: run_id must be primary_key"
                    )
                if c["name"] not in fnames:
                    raise RuntimeError(
                        f"I cannot reconcile the problemspace {self.pspace.name} with its database: extra column {c['name']}"
                    )
                fnames.remove(c["name"])

            if len(fnames) > 0:
                raise RuntimeError(
                    f"I cannot reconcile the problemspace {self.pspace.name} with its database: missing features {fnames}"
                )

            return self.reflect_db()

    def feature_to_column(self, feature: Feature, pk=False):
        # TODO: default is not actually writing to SQLAlchemy column object rn
        # does this even matter?
        return Column(
            feature.name,
            feature_to_alchemy_types[feature.feature_type],
            primary_key=pk,
            default=feature.default,
            nullable=not feature.required,
        )

    def run_key_columns(self) -> list[Column]:
        cols: list[Column] = []
        for feature_name, feature in run_key_features().items():
            pk = False
            if feature_name == "run_id":
                pk = True
            cols.append(self.feature_to_column(feature=feature, pk=pk))
        return cols

    def instance_key_columns(self) -> list[Column]:
        cols: list[Column] = []
        for _, feature in self.pspace.instance_key.items():
            pk = False
            cols.append(self.feature_to_column(feature=feature, pk=pk))
        return cols

    def solver_key_columns(self) -> list[Column]:
        cols: list[Column] = []
        for _, feature in self.pspace.solver_key.items():
            pk = False
            cols.append(self.feature_to_column(feature=feature, pk=pk))
        return cols

    def output_key_columns(self) -> list[Column]:
        cols: list[Column] = []
        for _, feature in self.pspace.output_key.items():
            pk = False
            cols.append(self.feature_to_column(feature=feature, pk=pk))
        return cols

    def create_db(self) -> AlchemyWAPI:
        columns: list[Column] = self.run_key_columns()
        columns.extend(self.instance_key_columns())
        columns.extend(self.solver_key_columns())
        columns.extend(self.output_key_columns())
        metadata = MetaData()
        self.results_table = Table(_RESULTS_TABLE_NAME, metadata, *columns)
        metadata.create_all(self.engine)
        return AlchemyWAPI(self.pspace, self.engine, metadata)

    def reflect_db(self) -> AlchemyWAPI:
        metadata = MetaData()
        self.results_table = Table(
            _RESULTS_TABLE_NAME, metadata, autoload_with=self.engine
        )
        return AlchemyWAPI(self.pspace, self.engine, metadata)


def init_alchemy_api(pspace: ProblemSpace) -> AlchemyWAPI | None:
    af = AlchemyFactory(pspace)
    return af.check_and_init_db()


def main():
    from optiface.core.optispace import read_pspace_from_yaml
    import argparse

    parser = argparse.ArgumentParser(prog="test_dbm")
    parser.add_argument("problem", type=str)
    args = parser.parse_args()
    pspace_name = args.problem

    pspace = read_pspace_from_yaml(pspace_name)
    db_api = init_alchemy_api(pspace)

    if db_api:
        print(db_api.metadata)
        print(db_api.metadata.tables[_RESULTS_TABLE_NAME].columns)


if __name__ == "__main__":
    main()
